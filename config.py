# Your OpenAI API key.
OPENAI_API_KEY = ''
# Path to save YouTube downloads to.
YOUTUBE_PATH = './youtube_videos/'
# Path to save summaries to.
OUTPUT_PATH = './output/'


# Prompt to use when we did need to use extractive summarization.
TRUNCATED_PROMPT = """
Your task is to be a highly proficient AI at processing large video transcripts to produce detailed summaries.
Due to the length of the transcripts and your token length limits, the video transcript was preprocessed using extractive text summarization.
The extractive text summarization was performed by scoring each sentence's relatedness to each other, and choosing the sentences with the highest overall score.
For this reason, some of the extracted text may be missing key context.
Be sure to keep this in mind during your summation.
The first {num_front_sentences} and last {num_back_sentences} sentences were preserved for context.
Now, process the preprocessed video transcript to create an overall video summary, written in paragraphs.
The title of the video is {title}<|endofprompt|>
{text}<|endoftext|>
""".strip().replace('.\n', '. ')
# Promp to use when we did not need to use extractive text summarization.
UNTRUNCATED_PROMPT = """
Your task is to be a highly proficient AI at processing large video transcripts to produce detailed summaries. 
Process the provided video transcript to create an overall video summary, written in paragraphs. 
The title of the video is {title}<|endofprompt|>
{text}<|endoftext|>
""".strip().replace('.\n', '. ')



# Choose the pretrained Whisper model.
# Options: ['tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large']
WHISPER_MODEL = 'base.en'

# Use YouTube creator-provided captions, if available.
YOUTUBE_CAPTIONS = True
# Use YouTube auto-generated captions. Note that autogenerated captions tend to be much worse quality than Whisper.
YOUTUBE_AUTO_CAPTIONS = False


# NOTE: TEXT_TOKEN_LIMIT AND RESPONSE_TOKEN_LIMIT CANNOT ADD UP TO 4096 LIMIT for two reasons:
# 1. We only estimate token count by dividing character count by 4.
# 2. The prompt is also included in the token count (~200 tokens).

# Token limit for the text to be summarized by GPT. Remember that GPT-3's total limit is 4096, and you must leave room for it's response. Also, about 200 tokens of prompt are added on top of this.
TEXT_TOKEN_LIMIT = 2048
# Token limit for the summary returned by GPT. Remember that GPT-3's total limit is 4096, including this response length.
RESPONSE_TOKEN_LIMIT = 1024



# Number of front sentences to be preserved when doing extractive summarization.
FRONT_SENTENCES_PRESERVED = 5
# Number of back sentences to be preserved when doing extractive summarization.
BACK_SENTENCES_PRESERVED = 5



# Verbosity throughout processing
VERBOSE = False